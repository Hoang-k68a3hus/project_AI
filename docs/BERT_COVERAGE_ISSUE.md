# BERT Embedding Coverage Issue - Root Cause Analysis

## ğŸ“‹ TÃ³m táº¯t váº¥n Ä‘á»

**Váº¥n Ä‘á»**: BERT embeddings khÃ´ng bao phá»§ 100% items trong training matrix.

**Hiá»‡n tráº¡ng**:
- BERT embeddings: 2,244 products
- Training matrix: 1,423 items
- Coverage: 94.0% (1,338/1,423 matched)
- **85 items trong training matrix khÃ´ng cÃ³ BERT embeddings** (6.0%)

## ğŸ” Root Cause Analysis

### NguyÃªn nhÃ¢n chÃ­nh

1. **BERT embeddings Ä‘Æ°á»£c táº¡o tá»« `enriched_products.parquet`**
   - File nÃ y chá»©a **Táº¤T Cáº¢ products** trong database (2,244 products)
   - ÄÆ°á»£c táº¡o tá»« merge giá»¯a `products.csv` vÃ  `attributes.csv`
   - KhÃ´ng filter theo interactions

2. **Training matrix chá»‰ chá»©a products cÃ³ interactions**
   - ÄÆ°á»£c táº¡o tá»« `interactions.csv` sau khi filter users vÃ  items
   - Chá»‰ giá»¯ láº¡i products cÃ³ â‰¥3 interactions (cold-start filtering)
   - Káº¿t quáº£: 1,423 items

3. **Mismatch giá»¯a 2 nguá»“n dá»¯ liá»‡u**
   - 85 products cÃ³ interactions nhÆ°ng **KHÃ”NG cÃ³ trong `enriched_products.parquet`**
   - Hoáº·c cÃ³ trong enriched nhÆ°ng bá»‹ filter ra khi generate BERT embeddings
   - â†’ KhÃ´ng cÃ³ BERT embeddings cho 85 items nÃ y

### Táº¡i sao products cÃ³ interactions nhÆ°ng khÃ´ng cÃ³ trong enriched_products.parquet?

CÃ³ thá»ƒ do:

1. **Merge failure trong content enrichment**
   - Products khÃ´ng match vá»›i attributes (product_id mismatch)
   - Products bá»‹ drop do missing data
   - Products khÃ´ng cÃ³ trong `products.csv` hoáº·c `attributes.csv`

2. **Data version mismatch**
   - `enriched_products.parquet` Ä‘Æ°á»£c táº¡o tá»« version cÅ© cá»§a data
   - Interactions data Ä‘Æ°á»£c update sau khi enrichment cháº¡y
   - â†’ New products cÃ³ interactions nhÆ°ng chÆ°a cÃ³ embeddings

3. **Filtering trong BERT generation**
   - Script `generate_bert_embeddings.py` cÃ³ thá»ƒ filter má»™t sá»‘ products
   - Products vá»›i missing `bert_input_text` bá»‹ skip

## ğŸ’¡ Giáº£i phÃ¡p

### Option 1: Filter Training Matrix (Recommended) âœ…

**CÃ¡ch lÃ m**: Loáº¡i bá» 85 items khÃ´ng cÃ³ BERT embeddings khá»i training matrix.

**Æ¯u Ä‘iá»ƒm**:
- âœ… ÄÆ¡n giáº£n, nhanh
- âœ… Äáº£m báº£o 100% coverage
- âœ… KhÃ´ng cáº§n regenerate BERT embeddings
- âœ… Consistent data (táº¥t cáº£ items Ä‘á»u cÃ³ BERT)

**NhÆ°á»£c Ä‘iá»ƒm**:
- âŒ Máº¥t 85 items (6% cá»§a training items)
- âŒ Cáº§n re-run Task 01 data pipeline

**Implementation**:
```bash
# 1. Analyze coverage issue
python scripts/analyze_bert_coverage.py

# 2. Fix by filtering training matrix
python scripts/fix_bert_coverage.py --filter-training

# 3. Re-run Task 01 data pipeline
python -m recsys.cf.data.data --output data/processed
```

### Option 2: Regenerate BERT Embeddings

**CÃ¡ch lÃ m**: Táº¡o láº¡i BERT embeddings chá»‰ cho products cÃ³ trong training matrix.

**Æ¯u Ä‘iá»ƒm**:
- âœ… Giá»¯ láº¡i táº¥t cáº£ training items
- âœ… Smaller embedding file

**NhÆ°á»£c Ä‘iá»ƒm**:
- âŒ Cáº§n regenerate embeddings (tá»‘n thá»i gian)
- âŒ Náº¿u cÃ³ products má»›i, pháº£i regenerate láº¡i

**Implementation**:
```python
# Filter enriched_products.parquet to only include training items
import pandas as pd
import torch

# Load training item IDs
with open('data/processed/user_item_mappings.json', 'r') as f:
    mappings = json.load(f)
training_item_ids = set(int(k) for k in mappings['item_to_idx'].keys())

# Filter enriched products
enriched_df = pd.read_parquet('data/processed/enriched_products.parquet')
enriched_df = enriched_df[enriched_df['product_id'].isin(training_item_ids)]

# Save filtered enriched products
enriched_df.to_parquet('data/processed/enriched_products_filtered.parquet')

# Regenerate BERT embeddings
from recsys.cf.data.processing.embedding_generator import EmbeddingGenerator

generator = EmbeddingGenerator()
generator.process_and_save(
    input_path='data/processed/enriched_products_filtered.parquet',
    output_path='data/processed/content_based_embeddings/product_embeddings.pt'
)
```

### Option 3: Use Zero Vectors (Current Workaround)

**CÃ¡ch lÃ m**: Giá»¯ nguyÃªn, dÃ¹ng random initialization cho items khÃ´ng cÃ³ BERT.

**Æ¯u Ä‘iá»ƒm**:
- âœ… KhÃ´ng cáº§n thay Ä‘á»•i gÃ¬
- âœ… Works immediately

**NhÆ°á»£c Ä‘iá»ƒm**:
- âŒ 85 items khÃ´ng benefit tá»« BERT initialization
- âŒ CÃ³ thá»ƒ gÃ¢y NaN trong training (nhÆ° Ä‘Ã£ tháº¥y)

**Note**: ÄÃ¢y lÃ  cÃ¡ch hiá»‡n táº¡i, nhÆ°ng gÃ¢y ra NaN errors.

### Option 4: Fix Content Enrichment Pipeline

**CÃ¡ch lÃ m**: Äáº£m báº£o táº¥t cáº£ products cÃ³ interactions Ä‘á»u cÃ³ trong `enriched_products.parquet`.

**Æ¯u Ä‘iá»ƒm**:
- âœ… Fix root cause
- âœ… Prevent future issues

**NhÆ°á»£c Ä‘iá»ƒm**:
- âŒ Cáº§n investigate vÃ  fix merge logic
- âŒ CÃ³ thá»ƒ phá»©c táº¡p náº¿u cÃ³ data quality issues

**Implementation**: Check `recsys/cf/data/processing/content_enrichment.py`

## ğŸ“Š Impact Analysis

### Náº¿u filter training matrix (Option 1):

- **Items removed**: 85 (6.0%)
- **Interactions removed**: ~X interactions (cáº§n check)
- **Coverage after**: 100%
- **Training impact**: Minimal (6% items, nhÆ°ng cÃ³ thá»ƒ lÃ  cold items)

### Náº¿u regenerate BERT embeddings (Option 2):

- **Items kept**: 1,423 (100%)
- **BERT embeddings**: 1,423 (down from 2,244)
- **Coverage after**: 100%
- **Training impact**: None

## ğŸ¯ Recommendation

**Recommended**: **Option 1 - Filter Training Matrix**

**LÃ½ do**:
1. ÄÆ¡n giáº£n vÃ  nhanh nháº¥t
2. Äáº£m báº£o 100% coverage
3. 85 items (6%) cÃ³ thá»ƒ lÃ  cold items (Ã­t interactions)
4. Loss nhá» so vá»›i benefit cá»§a 100% coverage

**Steps**:
1. Run `scripts/analyze_bert_coverage.py` Ä‘á»ƒ confirm
2. Run `scripts/fix_bert_coverage.py --filter-training`
3. Re-run Task 01 data pipeline
4. Re-train BERT-Enhanced ALS
5. Verify 100% coverage

## ğŸ”§ Scripts Available

1. **`scripts/analyze_bert_coverage.py`**
   - Analyze coverage issue
   - Identify root cause
   - Show unmatched items

2. **`scripts/fix_bert_coverage.py`**
   - Fix coverage by filtering training matrix
   - Create backups
   - Update mappings

## ğŸ“ Notes

- **Current workaround** (zero vectors) gÃ¢y NaN errors
- **Best practice**: Ensure 100% coverage trÆ°á»›c khi train
- **Future**: Sync BERT generation vá»›i training data pipeline

## ğŸ”— Related Files

- `recsys/cf/data/processing/embedding_generator.py` - BERT embedding generation
- `recsys/cf/data/processing/content_enrichment.py` - Content enrichment
- `recsys/cf/model/bert_enhanced_als.py` - BERT-Enhanced ALS model
- `notebooks/Colab_BERT_ALS_Training_Complete.ipynb` - Training notebook

